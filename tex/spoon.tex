% To do:
% ------
% - Write a title and abstract.
% - Write an outline.
% - Fill in the outline.
% - Publish.
% - Wait for the call from Stockholm.

% Style notes:
% ------------
% - Uhhh.

\documentclass[modern]{aastex631}
\usepackage[utf8]{inputenc}
\graphicspath{{./}{figures/}}

% Hogg typesetting issues
\addtolength{\textheight}{0.8in}
\addtolength{\topmargin}{-0.4in}
\setlength{\parindent}{1.2\baselineskip} % seriously
\frenchspacing\raggedbottom\sloppy\sloppypar

% Math issues
\newcommand{\teff}{T_{\mathrm{eff}}}
\newcommand{\logg}{\log g}
\newcommand{\feh}{[\mathrm{Fe}/\mathrm{H}]}

\shorttitle{machine learning and stellar parameters}
\shortauthors{apw \& dwh}

\begin{document}

\title{Machine learning, data-driven models, regression, and stellar parameters}

\author{APW}
\author{DWH}
\author{others}

\begin{abstract}\noindent % seriously!
  Machine learning is having a huge impact in astrophysics.
  Nowhere is this more true than in the measurement of stellar parameters ($\teff$, $\logg$, $\feh$, and detailed abundances) from spectra (fluxes as a function of wavelength, or equivalents).
  In the language of regression, the stellar parameters are labels and the stellar spectra are features.
  Here we discuss some of the big successes in this space, and some of the important pitfalls and concerns.
  One success is that some data-driven methods are very fast, much faster than traditional physics-driven methods.
  Another success is that some data-driven methods appear to perform well at very low signal-to-noise.
  One pitfall is that many kinds of regressions effectively produce posterior inferences with the training set taking an unintended role as the prior pdf (or a sampling thereof).
  Another pitfall is that discriminative models sometimes learn more about correlations in the label space than they do relationships between features and labels.
  One concern is that machine-learning methods do not generally do well with missing data, realistic noise models, or respecting fundamental symmetries.
  In the long run, machine learning should be deployed to enhance human learning; we discuss the prospects for this possible future.
\end{abstract}

\section{Introduction} \label{sec:intro}

Hello World!

\section{Regression and models}

What is a regression?

What does an ML or stats person call a ``model''?

What is generative and what is discriminative?

Why is this latter distinction important?

What is known from a math / proof perspective, especially as regards risk and correlations in the label space?

\section{Data-driven models}

The Cannon: What does it do?

The Cannon: Interesting results wrt s/n? Interesting results wrt de-noising? Interesting results wrt size of the training set?

The Cannon: What are its limitations?

AstroNN: What does it do?

AstroNN: What does it do well?

AstroNN: What are its limitations?

Maybe shout out the phylogenetics stuff but I think it's out of scope?

\section{Emulators}

The Payne (it is an emulator, right?)

\section{Symmetries, likelihoods, priors, and missing data}

What are the important symmetries? One is the spectrograph resolution! Okay maybe it's not a symmetry.

ML cost functions are abominable.

ML regularizations are not priors.

How do various methods deal with missing data? Badly, if they are discriminative.

\section{Physics-aware methods; human learning}

There aren't any yet. But seriously; it isn't that hard. KORG?

How could we learn from what we are doing?

\section{Discussion}

Hello World!

\bibliography{sample631}{}
\bibliographystyle{aasjournal}

\end{document}
